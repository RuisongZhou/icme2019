{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from deepctr import SingleFeat\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from model import xDeepFM_MTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading training data\n",
      "==> Get sparse features and dense features\n",
      "==> Fill sparse and dense features\n",
      "==> Apply label encoder for sparse features and regularization for dense features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Generate feature list\n",
      "==>Split train data and test data\n",
      "==> Generate training input and test input\n",
      "==> Build model and compile\n",
      "==> Training model\n",
      "Train on 15697872 samples, validate on 3924468 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[4096,8,1152] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node cin_2/transpose_2}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@training_1/Adagrad/gradients/cin_2/transpose_2_grad/transpose\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cin_2/Reshape_1, training_1/Adagrad/gradients/cin_2/transpose_2_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node ConstantFoldingCtrl/loss_1/like_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch_0/_486}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1171_...d/Switch_0\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c2a239c2c62c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"==> Training model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m history = model.fit(train_model_input, train_labels, batch_size=4096, epochs=1,\n\u001b[1;32m---> 87\u001b[1;33m                     verbose=1, validation_data=(test_model_input, test_labels))\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[4096,8,1152] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node cin_2/transpose_2}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _class=[\"loc:@training_1/Adagrad/gradients/cin_2/transpose_2_grad/transpose\"], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](cin_2/Reshape_1, training_1/Adagrad/gradients/cin_2/transpose_2_grad/InvertPermutation)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node ConstantFoldingCtrl/loss_1/like_loss/broadcast_weights/assert_broadcastable/AssertGuard/Switch_0/_486}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1171_...d/Switch_0\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "final_track2_train_path = u\"D:\\\\Competition\\\\内容理解与推荐\\\\data\\\\train_set\\\\final_track2_train.txt\"\n",
    "\n",
    "loss_weights = [1, 1]   # 最后的loss权重\n",
    "VALIDATION_FRAC = 0.2  # 验证集数据比例\n",
    "\n",
    "print(\"==> Loading training data\")\n",
    "with open(final_track2_train_path, \"r\") as fp:\n",
    "    data = pd.read_csv(fp, sep='\\t', names=[\n",
    "        'uid', 'user_city', 'item_id', 'author_id', 'item_city', 'channel', 'finish',\n",
    "        'like', 'music_id', 'did', 'creat_time', 'video_duration'])\n",
    "\n",
    "'''\n",
    "该处原代码有append数据\n",
    "'''\n",
    "print(\"==> Get sparse features and dense features\")\n",
    "train_size = int(data.shape[0]*(1-VALIDATION_FRAC))  # 计算训练集的size\n",
    "sparse_features = ['uid', 'user_city', 'item_id', 'author_id', 'item_city', 'channel',\n",
    "                 'music_id', 'did']   # 稀疏的特征，category类型特征\n",
    "dense_features = ['video_duration']    # dense的特征，embedding式特征\n",
    "\n",
    "'''\n",
    "将稀疏特征中空的值填充-1，将dense特征中空的值填充0\n",
    "'''\n",
    "print(\"==> Fill sparse and dense features\")\n",
    "data[sparse_features] = data[sparse_features].fillna('-1',)\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "\n",
    "'''\n",
    "学习的目标为finish和like的概率\n",
    "'''\n",
    "target = ['finish', 'like']\n",
    "\n",
    "'''\n",
    "对稀疏特征进行LabelEncoder，将这些category的值映射成index\n",
    "'''\n",
    "print(\"==> Apply label encoder for sparse features and regularization for dense features\")\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0,1))                        # 对数据进行归一化\n",
    "data[dense_features] = mms.fit_transform(data[dense_features]) # 将dense数据归一化到(0,1)\n",
    "\n",
    "'''\n",
    "SingleFeat 是一个带有签名的namedtuple，SingleFeat(name, dimension)\n",
    "==> name : 特征名称\n",
    "==> dimension : 独特特征的个数(对于稀疏特征)，任何值(对于dense特征)\n",
    "'''\n",
    "print(\"==> Generate feature list\")\n",
    "sparse_feature_list = [SingleFeat(feat, data[feat].nunique())\n",
    "                       for feat in sparse_features]\n",
    "dense_feature_list = [SingleFeat(feat, 0)\n",
    "                      for feat in dense_features]\n",
    "\n",
    "'''\n",
    "获取训练集和测试集\n",
    "'''\n",
    "print(\"==>Split train data and test data\")\n",
    "train = data.iloc[:train_size]\n",
    "test = data.iloc[train_size:]\n",
    "\n",
    "'''\n",
    "训练集输入和测试集输入，其中DataFrame.values返回numpy.array类型的值，如果返回\n",
    "一列值，得到的是一维向量，如果是多列的值，那么是二维矩阵。下面应该返回的都是\n",
    "一维向量\n",
    "'''\n",
    "print(\"==> Generate training input and test input\")\n",
    "train_model_input = [train[feat.name].values for feat in sparse_feature_list] + \\\n",
    "        [train[feat.name].values for feat in dense_feature_list]\n",
    "test_model_input = [test[feat.name].values for feat in sparse_feature_list] + \\\n",
    "        [test[feat.name].values for feat in dense_feature_list]\n",
    "\n",
    "train_labels = [train[target[0]].values, train[target[1]].values]\n",
    "test_labels = [test[target[0]].values, test[target[1]].values]\n",
    "\n",
    "'''\n",
    "构建模型，传递含有sparse特征名和dense特征名的字典，返回tf.keras.Model类。\n",
    "然后compile模型训练参数\n",
    "'''\n",
    "print(\"==> Build model and compile\")\n",
    "model = xDeepFM_MTL({'sparse' : sparse_feature_list,\n",
    "                     'dense' : dense_feature_list})\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\", loss_weights=loss_weights)\n",
    "\n",
    "'''\n",
    "在训练集上迭代训练模型指定的轮数\n",
    "'''\n",
    "print(\"==> Training model\")\n",
    "history = model.fit(train_model_input, train_labels, batch_size=4096, epochs=1,\n",
    "                    verbose=1, validation_data=(test_model_input, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
