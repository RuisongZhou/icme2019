{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 测试集数据分析结果：\n",
    "  + 测试集总共有2761799个测试样本，有32615个用户数，用户数大于测试样本数。\n",
    "  + 测试集共有790304个items。\n",
    "2. final_track2_train.txt分析结果：\n",
    "\n",
    "| uid | user_city | item_id | author_id | item_city | channel | finish | like | music_id | did | creat_time | video_duration |\n",
    "|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\n",
    "| 用户id | 用户的城市 | 作品id | 视频的作者id | 作品城市 | 作品城市 | 作品来源 | 是否浏览完作品 | 是否对作品点赞 | 音乐id | 设备id | 作品发布时间 | 作品时长 | \n",
    "  > + 由于在这个表里面sparse feature全部都是one-hot形式，所以使用sklearn的LabelEncoder进行编码转化成index。\n",
    "  > + 对于表中的dense feature都是单值的形式，所以先对其进行归一化处理到(0,1)，然后再作为输入。\n",
    "\n",
    "3. track2_title.txt分析结果：\n",
    "  > + 每一行一个字典字符串，一个key是item_id，一个key是title_feature，需要对title_feature统计词数。\n",
    "```\n",
    "{\"item_id\": 4036886, \"title_features\": {\"a\": b}}\n",
    "```\n",
    "  > + 输出一个tuple，tuple\\[0\\]表示词汇的index列表，tuple\\[1\\]是对应词汇出现的次数\n",
    "\n",
    "4. track2_video_features.txt分析结果：\n",
    "  > + 每一行一个字典字符串，一个是key是item+_id，一个key是video_feature_dim_128，表示128维的视频表示。\n",
    "```\n",
    "{\"item_id\": 11274473, \"video_feature_dim_128\": [0, 128]}\n",
    "```\n",
    "  > + 对于这个视频信息，可以通过两种方式输入模型，一种是通过全连接层，映射成field embedding的维度作为输入。另外一种是将embedding的每一维作为一个dense feature，然后对这个dense feature作为输入。\n",
    "  > + 暂定整体做一个向量输入\n",
    "\n",
    "5. track2_face_attrs.txt分析结果：\n",
    "  > 每一行是一个字典字符串\n",
    "```\n",
    "{\"item_id\": 6603879, \"face_attrs\": [{\"gender\": 0, \"beauty\": 0.53,\"relative_position\":[0.4306, 0.3203, 0.3333, 0.2969]}]}\n",
    "```\n",
    "  > + sparse feature直接one-hot，dense feature归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_track2_train_path = \"D:\\Competition\\内容理解与推荐\\data\\train_set\\final_track2_train.txt\"\n",
    "track2_title_path = \"D:\\Competition\\内容理解与推荐\\data\\train_set\\track2_title.txt\"\n",
    "track2_face_attrs = \"D:\\Competition\\内容理解与推荐\\data\\train_set\\track2_face_attrs.txt\"\n",
    "track2_video_features_path = \"D:\\Competition\\内容理解与推荐\\data\\train_set\\track2_video_features.txt\"\n",
    "test_data_path = \"./data/result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowFinalTrackInfo(final_track_path):\n",
    "    with codecs.open(final_track_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        content = fp.read()\n",
    "    num = content.count(\"\\n\")+1\n",
    "    \n",
    "    print(\"==> final_track样本个数 : %d\" % num)\n",
    "\n",
    "def ShowTestDataInfo(test_data_path):\n",
    "    df = pd.read_csv(test_data_path, encoding=\"utf-8\")\n",
    "    \n",
    "    print(\"==> 测试集样本个数 : %d\" % len(df))\n",
    "    print(\"==> 测试集用户个数 : %d\" % len(set(df[\"uid\"])))\n",
    "    print(\"==> 测试集item个数 : %d\" % len(set(df[\"item_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> The number of test samples : 2761799\n",
      "==> The number of users : 32615\n",
      "==> The number of items : 790304\n"
     ]
    }
   ],
   "source": [
    "ShowDataInfo(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生FFM训练文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "process_path = \"/disk/private-data/ICME2019/process\"\n",
    "split_num = 5\n",
    "target = [\"finish\", \"like\"]\n",
    "\n",
    "def transform(line):\n",
    "    line = line.split(\",\")\n",
    "    line = [line[0]] + [\"%d:%s\"%(i,j) for i,j in zip(range(11), line[1:])]\n",
    "    return \",\".join(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Process finish\n",
      "==> Process 1 train data\n",
      "==> Process 2 train data\n",
      "==> Process 3 train data\n",
      "==> Process 4 train data\n",
      "==> Process 5 train data\n",
      "==> Process like\n",
      "==> Process 1 train data\n",
      "==> Process 2 train data\n",
      "==> Process 3 train data\n",
      "==> Process 4 train data\n",
      "==> Process 5 train data\n"
     ]
    }
   ],
   "source": [
    "for tar in target:\n",
    "    print(\"==> Process %s\" % tar)\n",
    "    for i in range(split_num):\n",
    "        print(\"==> Process %d train data\" % (i+1))\n",
    "        train_path = os.path.join(process_path, \"FM_%s_train%d.txt\"%(tar, i+1))\n",
    "        FFM_path = os.path.join(process_path, \"FFM_%s_train%d.txt\"%(tar, i+1))\n",
    "        with open(train_path, \"r\") as fp:\n",
    "            content = fp.read().split(\"\\n\")\n",
    "        content = list(map(transform, content))\n",
    "        with open(FFM_path, \"w\") as fp:\n",
    "            fp.write(\"\\n\".join(content))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Process like\n"
     ]
    }
   ],
   "source": [
    "tar = \"finish\"\n",
    "print(\"==> Process %s\" % tar)\n",
    "train_path = os.path.join(process_path, \"FM_%s_valid.txt\"%tar)\n",
    "FFM_path = os.path.join(process_path, \"FFM_%s_valid.txt\"%tar)\n",
    "with open(train_path, \"r\") as fp:\n",
    "    content = fp.read().split(\"\\n\")\n",
    "content = list(map(transform, content))\n",
    "# with open(FFM_path, \"w\") as fp:\n",
    "#     fp.write(\"\\n\".join(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FFM_path, \"w\") as fp:\n",
    "     fp.write(\"\\n\".join(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
